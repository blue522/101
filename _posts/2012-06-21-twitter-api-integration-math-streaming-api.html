---
layout: post
title: 'Twitter API Integration Math: Streaming API'
url: http://apivoice.com/2012/06/21/twitter-api-integration-math-streaming-api/
image: http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/blog/streaming-matrix.jpg
---

<p>
I&rsquo;m continuing my blog series on using the Twitter API for my new API ranking and monitoring platform.  To begin, I did the math necessary to understand how I needed to use the Twitter API for my project.  Next, using the Twitter REST API, I tried to accomplish what I needed, quickly realizing the API rate limits would quickly prevent me from getting all the Tweets I needed.
Next up, the Twitter Streaming API.  The Twitter Streaming API give developers low latency, persistent access to Twitter's global stream of Tweet data, allowing Tweets to be pushed in real-time, without any of the overhead associated with polling a REST endpoint.  The streaming API has a technical learning curve above the REST API, but I used a PHP client library called Phirehose, which made getting up and running very easy.
The Twitter Streaming API provides three types of streams:

Public Streams - Streams of the public data flowing through Twitter. Suitable for following specific users or topics, and data mining
User Streams - Single-user streams, containing roughly all of the data corresponding with a single user's view of Twitter
Site Streams - The multi-user version of user streams. Site streams are intended for servers which must connect to Twitter on behalf of many users

For the purposes of my API ranking and monitoring platform I&rsquo;m just using public streams.  Using Phirehose I was able to set two types of connections with the Twitter Streaming API:

setTrack() - Track on specific keywords, #hashtags and @mentions
setFollow() - Follow specific Twitter users, getting all their Tweets

After going through all 6000+ of the APIs in the ProgrammableWeb directory, I have 1374 total Twitter accounts that I can follow and get mentions for.  However to really dial-in my API monitoring and ranking system I&rsquo;m going to focus in on 381 of what I consider to be the grade A and B APIs, for now.
With this in mind, I setup my Twitter API filters to track on 450 keywords, #hashtags and @mentions and directly follow the Twitter accounts of 381 APIs.  After initiating a persistent connection with the streaming API, the Tweets begin to flow in.  Its averaging about 400 Tweets per second at this track and follow volume.  When I cranked it up to 1000 Twitter accounts, it wouldn&rsquo;t reliably maintain a connection.  I can&rsquo;t tell if its technical on my end or a limitation on Twitter&rsquo;s end.  I will diagnose further in the future.

The Twitter Streaming API appears to give me what I need to pull in the Tweets necessary for my API ranking and monitoring, I still need to figure out if scaling the volume actually goes beyond the 1% volume limitation imposed by Twitter on the streaming API.  Its really hard to tell.  While the Twitter Streaming API is great for pulling these Tweets in real-time, it can only be applied for the "real-time now", not the past.  Once a moment passes and if I didn&rsquo;t capture a Tweet either because it wasn&rsquo;t defined in my filters or because the connection dropped, I have to use the Twitter REST API to retrieve it--putting me back in square one with the limitations of the REST API.
In my next post I will talk about how I have to reconcile between the Twitter Streaming and REST APIs to make sure I got all the Tweets I need, then I will explore the other options provided to me by Twitter reseller partners Gnip and Datasift, then I will summarize what I&rsquo;ve learned throughout this process.</p>
